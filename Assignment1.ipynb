{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import codecs\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(dir):\n",
    "    rt = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for name in files:\n",
    "            rt.append(os.path.join(root, name))\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "computer=[]\n",
    "recreational=[]\n",
    "science=[]\n",
    "talks=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list_files('/Users\\dft\\Downloads\\isanka\\datas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_files(files):\n",
    "    for file in files:\n",
    "        if \"comp\" in file:\n",
    "            computer.append(file)\n",
    "        elif \"rec\" in file:\n",
    "            recreational.append(file)\n",
    "        elif \"sci\" in file:\n",
    "            science.append(file)\n",
    "        elif \"talk\" in file:\n",
    "            talks.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_files(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_train,comp_test = train_test_split(computer, train_size=0.7,test_size=0.3, random_state=42)\n",
    "rec_train, rec_test = train_test_split(recreational, train_size=0.7,test_size=0.3, random_state=42)\n",
    "sci_train, sci_test = train_test_split(science, train_size=0.7,test_size=0.3, random_state=42)\n",
    "talk_train,talk_test = train_test_split(talks, train_size=0.7,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(file):\n",
    "    lt=[]\n",
    "    wtxt = codecs.open(file,encoding='utf-8', errors='ignore').read()\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    tokenizer = RegexpTokenizer(r'[a-z,A-Z]{2,}')\n",
    "    token=tokenizer.tokenize(wtxt)\n",
    "    for w in token:\n",
    "        w = w.translate(str.maketrans('','',string.punctuation))\n",
    "        if w.lower() not in stopWords and w.lower() not in lt:\n",
    "            lt.append(w)\n",
    "    return lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "compTrain=[]\n",
    "recTrain=[]\n",
    "sciTrain=[]\n",
    "talkTrain=[]\n",
    "compTest=[]\n",
    "recTest=[]\n",
    "sciTest=[]\n",
    "talkTest=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in comp_train:\n",
    "    compTrain.append(process_files(file))\n",
    "for file in rec_train:\n",
    "    recTrain.append(process_files(file))\n",
    "for file in sci_train:\n",
    "    sciTrain.append(process_files(file))\n",
    "for file in talk_train:\n",
    "    talkTrain.append(process_files(file))\n",
    "for file in comp_test:\n",
    "    compTest.append(process_files(file))\n",
    "for file in rec_test:\n",
    "    recTest.append(process_files(file))\n",
    "for file in sci_test:\n",
    "    sciTest.append(process_files(file))\n",
    "for file in talk_test:\n",
    "    talkTest.append(process_files(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Iterable\n",
    "def flatten(list):\n",
    "    for i in list:\n",
    "        for j in i:\n",
    "            yield j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_list(lst):\n",
    "    lt=[]\n",
    "    lt=flatten(lst)\n",
    "    llt=list(lt)\n",
    "    return llt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_csv(datalist,dataset):\n",
    "        l=flat_list(datalist)\n",
    "        data=[]\n",
    "        for dt in l:\n",
    "             if dt not in data:\n",
    "                     data.append(dt)\n",
    "    \n",
    "        count_vect = CountVectorizer()\n",
    "        X_train_counts = count_vect.fit_transform(data)\n",
    "        vectorizer = CountVectorizer(max_features=1000)\n",
    "        trans = vectorizer.fit_transform(data)\n",
    "        features=vectorizer.get_feature_names()\n",
    "        df = pd.DataFrame(trans.toarray(), columns = features)\n",
    "        df.to_csv(dataset+'_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryList=['compTrain','recTrain','sciTrain','talkTrain','compTest','recTest','sciTest','talkTest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "    convert_csv(compTrain,categoryList[0])\n",
    "    convert_csv(recTrain,categoryList[1])\n",
    "    convert_csv(sciTrain,categoryList[2])\n",
    "    convert_csv(talkTrain,categoryList[3])\n",
    "    convert_csv(compTest,categoryList[4])\n",
    "    convert_csv(recTest,categoryList[5])\n",
    "    convert_csv(sciTest,categoryList[6])\n",
    "    convert_csv(talkTest,categoryList[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
